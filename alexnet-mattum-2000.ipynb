{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-08T09:51:20.303566Z","iopub.status.idle":"2022-03-08T09:51:20.304357Z","shell.execute_reply.started":"2022-03-08T09:51:20.304071Z","shell.execute_reply":"2022-03-08T09:51:20.304099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:51:29.582393Z","iopub.execute_input":"2022-03-08T09:51:29.582846Z","iopub.status.idle":"2022-03-08T09:51:36.986245Z","shell.execute_reply.started":"2022-03-08T09:51:29.5828Z","shell.execute_reply":"2022-03-08T09:51:36.984999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data\ntrain_datagen_with_no_transforms = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255)\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1./255)\n\ntrain_generator = train_datagen_with_no_transforms.flow_from_directory(\n    '../input/emotion-detection-fer/train',\n    target_size=(32,32),\n    batch_size=32,\n    class_mode=\"sparse\"\n)\nvalidation_generator = val_datagen.flow_from_directory(\n    '../input/emotion-detection-fer/test',\n    target_size=(32,32),\n    batch_size=32,\n    class_mode=\"sparse\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:51:39.521047Z","iopub.execute_input":"2022-03-08T09:51:39.521366Z","iopub.status.idle":"2022-03-08T09:52:01.797105Z","shell.execute_reply.started":"2022-03-08T09:51:39.521335Z","shell.execute_reply":"2022-03-08T09:52:01.795685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = next(validation_generator)\nsample_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:52:01.799171Z","iopub.execute_input":"2022-03-08T09:52:01.799824Z","iopub.status.idle":"2022-03-08T09:52:02.041002Z","shell.execute_reply.started":"2022-03-08T09:52:01.79975Z","shell.execute_reply":"2022-03-08T09:52:02.039746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_train_samples = train_generator.samples\nnb_val_samples = validation_generator.samples\ntrain_generator.samples","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:52:04.003833Z","iopub.execute_input":"2022-03-08T09:52:04.004123Z","iopub.status.idle":"2022-03-08T09:52:04.012159Z","shell.execute_reply.started":"2022-03-08T09:52:04.004094Z","shell.execute_reply":"2022-03-08T09:52:04.011394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALEXNET SEQUENTIAL","metadata":{}},{"cell_type":"code","source":"input_shape=(32,32, 3) \nnum_classes = 7\n# AlexNET model\nseq_alex = models.Sequential()\n#seq_alex.add() # input shape must be specified according to the input data dimension\n#seq_alex.add()\n\nseq_alex.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n                        padding= 'valid', activation= 'relu',\n                        input_shape= input_shape,\n                        kernel_initializer= 'he_normal'))\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None))\n\nseq_alex.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None)) \n\nseq_alex.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None))\n\nseq_alex.add(Flatten())\nseq_alex.add(Dense(4096, activation= 'relu'))\nseq_alex.add(Dense(4096, activation= 'relu'))\nseq_alex.add(Dense(1000, activation= 'relu'))\nseq_alex.add(Dense(num_classes, activation= 'softmax'))\n\nseq_alex.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:08:45.787211Z","iopub.execute_input":"2022-03-08T08:08:45.787656Z","iopub.status.idle":"2022-03-08T08:08:46.03973Z","shell.execute_reply.started":"2022-03-08T08:08:45.787582Z","shell.execute_reply":"2022-03-08T08:08:46.038885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nseq_alex.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T07:17:15.289392Z","iopub.execute_input":"2022-03-08T07:17:15.290337Z","iopub.status.idle":"2022-03-08T07:17:15.301639Z","shell.execute_reply.started":"2022-03-08T07:17:15.290285Z","shell.execute_reply":"2022-03-08T07:17:15.300711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = seq_alex.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T07:17:19.681704Z","iopub.execute_input":"2022-03-08T07:17:19.682177Z","iopub.status.idle":"2022-03-08T07:19:19.84214Z","shell.execute_reply.started":"2022-03-08T07:17:19.682114Z","shell.execute_reply":"2022-03-08T07:19:19.841138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_names = [layer.name for layer in seq_alex.layers]\nlayer_names","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:27:19.841921Z","iopub.execute_input":"2022-03-08T06:27:19.842275Z","iopub.status.idle":"2022-03-08T06:27:19.849451Z","shell.execute_reply.started":"2022-03-08T06:27:19.842234Z","shell.execute_reply":"2022-03-08T06:27:19.8488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_alex.layers","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:27:33.430644Z","iopub.execute_input":"2022-03-08T06:27:33.431195Z","iopub.status.idle":"2022-03-08T06:27:33.437867Z","shell.execute_reply.started":"2022-03-08T06:27:33.431156Z","shell.execute_reply":"2022-03-08T06:27:33.436825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_outputs = [layer.output for layer in seq_alex.layers]\nlayer_outputs","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:28:24.648635Z","iopub.execute_input":"2022-03-08T06:28:24.648939Z","iopub.status.idle":"2022-03-08T06:28:24.656299Z","shell.execute_reply.started":"2022-03-08T06:28:24.648905Z","shell.execute_reply":"2022-03-08T06:28:24.655667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_map_model = tf.keras.models.Model(seq_alex.input, layer_outputs)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:32:50.830483Z","iopub.execute_input":"2022-03-08T06:32:50.830811Z","iopub.status.idle":"2022-03-08T06:32:50.839715Z","shell.execute_reply.started":"2022-03-08T06:32:50.830775Z","shell.execute_reply":"2022-03-08T06:32:50.838833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path= r\"../input/emotion-detection-fer/test/happy/im1.png\"\nimg = tf.keras.utils.load_img(image_path, target_size=(32, 32))  \ninput = tf.keras.utils.img_to_array(img)                           \ninput = input.reshape((1,) + input.shape)                   \ninput /= 255.0","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:43:09.839258Z","iopub.execute_input":"2022-03-08T06:43:09.840081Z","iopub.status.idle":"2022-03-08T06:43:09.848719Z","shell.execute_reply.started":"2022-03-08T06:43:09.840029Z","shell.execute_reply":"2022-03-08T06:43:09.847895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_maps = feature_map_model.predict(input)\nfeature_maps","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:44:05.765761Z","iopub.execute_input":"2022-03-08T06:44:05.766072Z","iopub.status.idle":"2022-03-08T06:44:05.876189Z","shell.execute_reply.started":"2022-03-08T06:44:05.766039Z","shell.execute_reply":"2022-03-08T06:44:05.875362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer_name, feature_map in zip(layer_names, feature_maps):print(f\"The shape of the {layer_name} is =======>> {feature_map.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:44:14.114318Z","iopub.execute_input":"2022-03-08T06:44:14.114908Z","iopub.status.idle":"2022-03-08T06:44:14.121911Z","shell.execute_reply.started":"2022-03-08T06:44:14.114865Z","shell.execute_reply":"2022-03-08T06:44:14.120661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_map.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:49:28.662449Z","iopub.execute_input":"2022-03-08T06:49:28.662822Z","iopub.status.idle":"2022-03-08T06:49:28.669471Z","shell.execute_reply.started":"2022-03-08T06:49:28.662784Z","shell.execute_reply":"2022-03-08T06:49:28.668682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_map[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-08T06:53:07.173855Z","iopub.execute_input":"2022-03-08T06:53:07.174242Z","iopub.status.idle":"2022-03-08T06:53:07.181773Z","shell.execute_reply.started":"2022-03-08T06:53:07.1742Z","shell.execute_reply":"2022-03-08T06:53:07.1809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_alex.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nseq_alex.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALEXNET FUNCTIONAL API","metadata":{}},{"cell_type":"code","source":"input_shape=(32,32,3)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np \n# Do\n# AlexNET model with functional API\ninputs = tf.keras.layers.Input(shape=input_shape) # input shape must be specified according to the input data dimension\n#x = tf.keras.layers.Conv2D()(inputs)\n#x = tf.keras.layers.MaxPool2D()(x)\n\n#functional_alex = models.Model(inputs=inputs, outputs=)\n\n#X_input = Input(input_shape)   \nX = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(inputs)\nX = BatchNormalization(axis = 3 , name = \"bn0\")(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max0',padding='same')(X)\n    \nX = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\nX = BatchNormalization(axis = 3 ,name='bn1')(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max1',padding='same')(X)\n    \nX = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\nX = BatchNormalization(axis = 3, name = 'bn2')(X)\nX = Activation('relu')(X)\n    \nX = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\nX = BatchNormalization(axis = 3, name = 'bn3')(X)\nX = Activation('relu')(X)\n    \nX = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\nX = BatchNormalization(axis = 3, name = 'bn4')(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max2',padding='same')(X)\n    \nX = Flatten()(X)\n    \nX = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n    \nX = Dense(4096, activation = 'relu', name = 'fc1')(X) \n    \nX = Dense(1000,activation='softmax',name = 'fc2')(X) \n    \nmodel = Model(inputs = inputs, outputs = X, name='AlexNet')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:52:35.076638Z","iopub.execute_input":"2022-03-08T09:52:35.076968Z","iopub.status.idle":"2022-03-08T09:52:35.492346Z","shell.execute_reply.started":"2022-03-08T09:52:35.076936Z","shell.execute_reply":"2022-03-08T09:52:35.491187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:52:53.688088Z","iopub.execute_input":"2022-03-08T09:52:53.688386Z","iopub.status.idle":"2022-03-08T09:52:53.708904Z","shell.execute_reply.started":"2022-03-08T09:52:53.688343Z","shell.execute_reply":"2022-03-08T09:52:53.707993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:52:57.972122Z","iopub.execute_input":"2022-03-08T09:52:57.972676Z","iopub.status.idle":"2022-03-08T09:53:02.008448Z","shell.execute_reply.started":"2022-03-08T09:52:57.97264Z","shell.execute_reply":"2022-03-08T09:53:02.004909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALEXNET SEQUENTIAL API","metadata":{}},{"cell_type":"code","source":"#Importing library\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nimport numpy as np\n\nnp.random.seed(1000)\n\n#Instantiation\nAlexNet = Sequential()\n\n#1st Convolutional Layer\nAlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#2nd Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#3rd Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#4th Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#5th Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#Passing it to a Fully Connected layer\nAlexNet.add(Flatten())\n# 1st Fully Connected Layer\nAlexNet.add(Dense(4096, input_shape=(32,32,3,)))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nAlexNet.add(Dropout(0.4))\n\n#2nd Fully Connected Layer\nAlexNet.add(Dense(4096))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#3rd Fully Connected Layer\nAlexNet.add(Dense(1000))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#Output Layer\nAlexNet.add(Dense(10))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('softmax'))\n\n#Model Summary\nAlexNet.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:08.037691Z","iopub.execute_input":"2022-03-08T09:53:08.038005Z","iopub.status.idle":"2022-03-08T09:53:08.538737Z","shell.execute_reply.started":"2022-03-08T09:53:08.037971Z","shell.execute_reply":"2022-03-08T09:53:08.536909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AlexNet.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:12.674889Z","iopub.execute_input":"2022-03-08T09:53:12.675186Z","iopub.status.idle":"2022-03-08T09:53:12.687585Z","shell.execute_reply.started":"2022-03-08T09:53:12.675154Z","shell.execute_reply":"2022-03-08T09:53:12.686223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) ","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:15.799075Z","iopub.execute_input":"2022-03-08T09:53:15.79934Z","iopub.status.idle":"2022-03-08T09:53:15.804356Z","shell.execute_reply.started":"2022-03-08T09:53:15.799311Z","shell.execute_reply":"2022-03-08T09:53:15.803486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:18.471423Z","iopub.execute_input":"2022-03-08T09:53:18.471768Z","iopub.status.idle":"2022-03-08T09:53:18.477094Z","shell.execute_reply.started":"2022-03-08T09:53:18.471721Z","shell.execute_reply":"2022-03-08T09:53:18.475997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the model\nAlexNet.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:26.853214Z","iopub.execute_input":"2022-03-08T09:53:26.853515Z","iopub.status.idle":"2022-03-08T09:53:40.746952Z","shell.execute_reply.started":"2022-03-08T09:53:26.853485Z","shell.execute_reply":"2022-03-08T09:53:40.745715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:53:42.785219Z","iopub.execute_input":"2022-03-08T09:53:42.785504Z","iopub.status.idle":"2022-03-08T09:53:43.124503Z","shell.execute_reply.started":"2022-03-08T09:53:42.785474Z","shell.execute_reply":"2022-03-08T09:53:43.122905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = AlexNet.predict(validation_generator)\npredictions = predictions.reshape(1,-1)[0]\npredictions[:15]","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:54:11.333888Z","iopub.execute_input":"2022-03-08T09:54:11.334178Z","iopub.status.idle":"2022-03-08T09:54:50.318047Z","shell.execute_reply.started":"2022-03-08T09:54:11.334149Z","shell.execute_reply":"2022-03-08T09:54:50.316306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = np.nonzero(predictions == validation_generator)[0]\nincorrect = np.nonzero(predictions != validation_generator)[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:56:54.429033Z","iopub.execute_input":"2022-03-08T09:56:54.429653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], validation_generator[c]))\n    plt.tight_layout()\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-03-08T09:55:36.558566Z","iopub.execute_input":"2022-03-08T09:55:36.559076Z","iopub.status.idle":"2022-03-08T09:55:36.596963Z","shell.execute_reply.started":"2022-03-08T09:55:36.559039Z","shell.execute_reply":"2022-03-08T09:55:36.594354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Iterate through all the layers of the model\nfor layer in model.layers:\n    if 'Conv' in layer.name:\n        weights, bias= layer.get_weights()\n        print(layer.name, filters.shape)\n        \n        #normalize filter values between  0 and 1 for visualization\n        f_min, f_max = weights.min(), weights.max()\n        filters = (weights - f_min) / (f_max - f_min)  \n        print(filters.shape[3])\n        filter_cnt=1\n        \n        #plotting all the filters\n        for i in range(filters.shape[3]):\n            #get the filters\n            filt=filters[:,:,:, i]\n            #plotting each of the channel, color image RGB channels\n            for j in range(filters.shape[0]):\n                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n                ax.set_xticks([])\n                ax.set_yticks([])\n                plt.imshow(filt[:,:, j])\n                filter_cnt+=1\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-08T07:54:53.487298Z","iopub.execute_input":"2022-03-08T07:54:53.487579Z","iopub.status.idle":"2022-03-08T07:54:53.497958Z","shell.execute_reply.started":"2022-03-08T07:54:53.487549Z","shell.execute_reply":"2022-03-08T07:54:53.497029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path='../input/emotion-detection-fer/test/happy/im1.png' \n# Define a new Model, Input= image \n# Output= intermediate representations for all layers in the  \n# previous model after the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n#Load the input image\nimg = tf.keras.utils.load_img(img_path, target_size=(32, 32))\n# Convert ht image to Array of dimension (32,32,3)\nx   = tf.keras.utils.img_to_array(img)                           \nx   = x.reshape((1,) + x.shape)\n# Rescale by 1/255\nx /= 255.0\n# Let's run input image through our vislauization network\n# to obtain all intermediate representations for the image.\nsuccessive_feature_maps = visualization_model.predict(x)\n# Retrieve are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n    print(feature_map.shape)\n    if len(feature_map.shape) == 4:\n        # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n   \n        n_features = feature_map.shape[-1]  # number of features in the feature map\n        size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    # Postprocess the feature to be visually palatable\n    for i in range(n_features):\n        x  = feature_map[0, :, :, i]\n        x -= x.mean()\n        x /= x.std ()\n        x *=  64\n        x += 128\n        x  = np.clip(x, 0, 255).astype('uint8')\n        # Tile each filter into a horizontal grid\n        display_grid[:, i * size : (i + 1) * size] = x\n# Display the grid\n    scale = 20. / n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' )","metadata":{"execution":{"iopub.status.busy":"2022-03-08T07:54:57.204514Z","iopub.execute_input":"2022-03-08T07:54:57.205534Z","iopub.status.idle":"2022-03-08T07:55:01.323959Z","shell.execute_reply.started":"2022-03-08T07:54:57.205484Z","shell.execute_reply":"2022-03-08T07:55:01.322658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}