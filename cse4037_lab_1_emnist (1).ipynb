{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "cse4037-lab-1-emnist.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers.core import Dense, Activation \n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "np.random.seed(1671)  # for reproducibility"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T05:34:39.971181Z",
          "iopub.execute_input": "2022-01-09T05:34:39.971403Z",
          "iopub.status.idle": "2022-01-09T05:34:46.122316Z",
          "shell.execute_reply.started": "2022-01-09T05:34:39.971377Z",
          "shell.execute_reply": "2022-01-09T05:34:46.121449Z"
        },
        "trusted": true,
        "id": "d8l--Ed_zQvT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T06:13:56.960147Z",
          "iopub.execute_input": "2022-01-09T06:13:56.960422Z",
          "iopub.status.idle": "2022-01-09T06:13:56.965064Z",
          "shell.execute_reply.started": "2022-01-09T06:13:56.960394Z",
          "shell.execute_reply": "2022-01-09T06:13:56.964416Z"
        },
        "trusted": true,
        "id": "y-bzc5OFzQvV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install extra-keras-datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T05:40:21.746903Z",
          "iopub.execute_input": "2022-01-09T05:40:21.747337Z",
          "iopub.status.idle": "2022-01-09T05:40:33.386622Z",
          "shell.execute_reply.started": "2022-01-09T05:40:21.747301Z",
          "shell.execute_reply": "2022-01-09T05:40:33.385628Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJjO6vWRzQvW",
        "outputId": "37c8888b-6658-43f0-8937-4352e5825359"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: extra-keras-datasets in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->extra-keras-datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->extra-keras-datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->extra-keras-datasets) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra-keras-datasets) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra-keras-datasets) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from extra_keras_datasets import emnist\n",
        "(input_train, target_train), (input_test, target_test) = emnist.load_data(type='balanced')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T05:40:41.069156Z",
          "iopub.execute_input": "2022-01-09T05:40:41.069445Z",
          "iopub.status.idle": "2022-01-09T05:41:29.324641Z",
          "shell.execute_reply.started": "2022-01-09T05:40:41.069414Z",
          "shell.execute_reply": "2022-01-09T05:41:29.323800Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAlpYlmnzQvX",
        "outputId": "88eb39cf-9dd1-415c-a821-53610db40dcc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loading dataset = emnist\n",
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data: shuffled and split between train and test sets\n",
        "# (X_train, y_train), (X_test, y_test) = keras.datasets.emnist.load_data()\n",
        "# X_train is input_train, y_train is target_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T06:12:24.626307Z",
          "iopub.execute_input": "2022-01-09T06:12:24.626621Z",
          "iopub.status.idle": "2022-01-09T06:12:24.630449Z",
          "shell.execute_reply.started": "2022-01-09T06:12:24.626589Z",
          "shell.execute_reply": "2022-01-09T06:12:24.629609Z"
        },
        "trusted": true,
        "id": "f7fbTx2GzQvZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 47 # number of outputs = number of digits\n",
        "OPTIMIZER = Adam() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 1024\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "#X_train is 112800 rows of 28x28 values --> reshaped in 112800 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = input_train.reshape(112800, RESHAPED)\n",
        "X_test = input_test.reshape(18800, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# normalize\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(target_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(target_test, NB_CLASSES)\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=OPTIMIZER,\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,\n",
        "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"Test score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T06:04:04.047748Z",
          "iopub.execute_input": "2022-01-09T06:04:04.048079Z",
          "iopub.status.idle": "2022-01-09T06:09:01.971928Z",
          "shell.execute_reply.started": "2022-01-09T06:04:04.048037Z",
          "shell.execute_reply": "2022-01-09T06:09:01.971032Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQC8gfn9zQva",
        "outputId": "48b5942e-0e41-4a88-e07b-1c7e22f5b392"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112800 train samples\n",
            "18800 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              803840    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 47)                48175     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 47)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901,615\n",
            "Trainable params: 1,901,615\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.8532 - accuracy: 0.7396 - val_loss: 0.5595 - val_accuracy: 0.8090\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.4809 - accuracy: 0.8366 - val_loss: 0.5073 - val_accuracy: 0.8293\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.3895 - accuracy: 0.8613 - val_loss: 0.4714 - val_accuracy: 0.8387\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.3350 - accuracy: 0.8762 - val_loss: 0.4607 - val_accuracy: 0.8408\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2868 - accuracy: 0.8909 - val_loss: 0.4769 - val_accuracy: 0.8415\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2548 - accuracy: 0.9003 - val_loss: 0.4970 - val_accuracy: 0.8388\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2285 - accuracy: 0.9091 - val_loss: 0.5035 - val_accuracy: 0.8408\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2063 - accuracy: 0.9157 - val_loss: 0.5197 - val_accuracy: 0.8411\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 32s 45ms/step - loss: 0.1881 - accuracy: 0.9236 - val_loss: 0.5354 - val_accuracy: 0.8447\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1738 - accuracy: 0.9283 - val_loss: 0.5655 - val_accuracy: 0.8434\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.1652 - accuracy: 0.9316 - val_loss: 0.5919 - val_accuracy: 0.8401\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1470 - accuracy: 0.9392 - val_loss: 0.6030 - val_accuracy: 0.8411\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1438 - accuracy: 0.9409 - val_loss: 0.6674 - val_accuracy: 0.8394\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1335 - accuracy: 0.9452 - val_loss: 0.6757 - val_accuracy: 0.8425\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1292 - accuracy: 0.9471 - val_loss: 0.6925 - val_accuracy: 0.8452\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1207 - accuracy: 0.9507 - val_loss: 0.7279 - val_accuracy: 0.8387\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 30s 43ms/step - loss: 0.1231 - accuracy: 0.9502 - val_loss: 0.7450 - val_accuracy: 0.8398\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1081 - accuracy: 0.9557 - val_loss: 0.7631 - val_accuracy: 0.8402\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1053 - accuracy: 0.9570 - val_loss: 0.8262 - val_accuracy: 0.8408\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1064 - accuracy: 0.9573 - val_loss: 0.8496 - val_accuracy: 0.8363\n",
            "588/588 [==============================] - 4s 6ms/step - loss: 0.9020 - accuracy: 0.8368\n",
            "Test score: 0.9020251035690308\n",
            "Test accuracy: 0.8367553353309631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For 20 epochs 128 batch size Adam() optimizer 1024 N_HIDDEN\n",
        "# Test accuracy=0.840691"
      ],
      "metadata": {
        "id": "6d-MV25mzQvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation=0.2 gives the best accuracy\n",
        "# NB_classes=47  (10 digits 37 letters)\n",
        "# vebose=1       shows progress bar "
      ],
      "metadata": {
        "id": "hITtIf1EzQvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_test.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T05:49:20.253675Z",
          "iopub.execute_input": "2022-01-09T05:49:20.254441Z",
          "iopub.status.idle": "2022-01-09T05:49:20.260645Z",
          "shell.execute_reply.started": "2022-01-09T05:49:20.254401Z",
          "shell.execute_reply": "2022-01-09T05:49:20.259682Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC0qaVIFzQvn",
        "outputId": "eee4ad80-29c5-4034-f66a-5c0fde1fa1fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18800, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 250 epoch 32 batch size \n",
        "# To check which optimizer Adam() or SGD() or RMSprop() gives the best accuracy\n",
        "# It is taking too long to run\n",
        "# 50 epoch 128 batch size is used to compare models"
      ],
      "metadata": {
        "id": "c-cKLXbxzQvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "NB_EPOCH = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 47 # number of outputs = number of digits/letters\n",
        "OPTIMIZER = Adam() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 1024\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "#X_train is 112800 rows of 28x28 values --> reshaped in 112800 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = input_train.reshape(112800, RESHAPED)\n",
        "X_test = input_test.reshape(18800, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# normalize\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(target_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(target_test, NB_CLASSES)\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=OPTIMIZER,\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,\n",
        "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"Test score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T06:01:46.179671Z",
          "iopub.execute_input": "2022-01-09T06:01:46.180545Z",
          "iopub.status.idle": "2022-01-09T06:01:46.186328Z",
          "shell.execute_reply.started": "2022-01-09T06:01:46.180505Z",
          "shell.execute_reply": "2022-01-09T06:01:46.185669Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hRR0B6TzQvp",
        "outputId": "ba4255b3-f5de-4a65-9040-1d7df43a8bd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112800 train samples\n",
            "18800 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 47)                48175     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 47)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901,615\n",
            "Trainable params: 1,901,615\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "705/705 [==============================] - 30s 43ms/step - loss: 0.8500 - accuracy: 0.7410 - val_loss: 0.5693 - val_accuracy: 0.8083\n",
            "Epoch 2/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.4789 - accuracy: 0.8368 - val_loss: 0.4933 - val_accuracy: 0.8315\n",
            "Epoch 3/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.3880 - accuracy: 0.8617 - val_loss: 0.4866 - val_accuracy: 0.8347\n",
            "Epoch 4/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.3302 - accuracy: 0.8779 - val_loss: 0.4738 - val_accuracy: 0.8418\n",
            "Epoch 5/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2891 - accuracy: 0.8902 - val_loss: 0.4725 - val_accuracy: 0.8423\n",
            "Epoch 6/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.2538 - accuracy: 0.9012 - val_loss: 0.4837 - val_accuracy: 0.8449\n",
            "Epoch 7/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2252 - accuracy: 0.9100 - val_loss: 0.5090 - val_accuracy: 0.8422\n",
            "Epoch 8/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.2075 - accuracy: 0.9157 - val_loss: 0.5267 - val_accuracy: 0.8422\n",
            "Epoch 9/50\n",
            "705/705 [==============================] - 31s 44ms/step - loss: 0.1911 - accuracy: 0.9214 - val_loss: 0.5465 - val_accuracy: 0.8392\n",
            "Epoch 10/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1714 - accuracy: 0.9302 - val_loss: 0.5693 - val_accuracy: 0.8410\n",
            "Epoch 11/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1564 - accuracy: 0.9352 - val_loss: 0.5895 - val_accuracy: 0.8420\n",
            "Epoch 12/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.1532 - accuracy: 0.9374 - val_loss: 0.6067 - val_accuracy: 0.8434\n",
            "Epoch 13/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.1426 - accuracy: 0.9407 - val_loss: 0.6443 - val_accuracy: 0.8413\n",
            "Epoch 14/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.1378 - accuracy: 0.9437 - val_loss: 0.6698 - val_accuracy: 0.8398\n",
            "Epoch 15/50\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1287 - accuracy: 0.9468 - val_loss: 0.7015 - val_accuracy: 0.8379\n",
            "Epoch 16/50\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1212 - accuracy: 0.9501 - val_loss: 0.7259 - val_accuracy: 0.8412\n",
            "Epoch 17/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1147 - accuracy: 0.9530 - val_loss: 0.7683 - val_accuracy: 0.8406\n",
            "Epoch 18/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1181 - accuracy: 0.9526 - val_loss: 0.7605 - val_accuracy: 0.8409\n",
            "Epoch 19/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1040 - accuracy: 0.9576 - val_loss: 0.8029 - val_accuracy: 0.8419\n",
            "Epoch 20/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1000 - accuracy: 0.9591 - val_loss: 0.8260 - val_accuracy: 0.8412\n",
            "Epoch 21/50\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.1006 - accuracy: 0.9594 - val_loss: 0.8874 - val_accuracy: 0.8396\n",
            "Epoch 22/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0967 - accuracy: 0.9616 - val_loss: 0.8824 - val_accuracy: 0.8420\n",
            "Epoch 23/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0918 - accuracy: 0.9633 - val_loss: 0.9083 - val_accuracy: 0.8444\n",
            "Epoch 24/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0919 - accuracy: 0.9635 - val_loss: 0.9940 - val_accuracy: 0.8375\n",
            "Epoch 25/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0925 - accuracy: 0.9642 - val_loss: 0.9597 - val_accuracy: 0.8433\n",
            "Epoch 26/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0865 - accuracy: 0.9658 - val_loss: 1.0039 - val_accuracy: 0.8375\n",
            "Epoch 27/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 0.9994 - val_accuracy: 0.8383\n",
            "Epoch 28/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0789 - accuracy: 0.9691 - val_loss: 1.0706 - val_accuracy: 0.8362\n",
            "Epoch 29/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0845 - accuracy: 0.9686 - val_loss: 1.1009 - val_accuracy: 0.8333\n",
            "Epoch 30/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 1.0864 - val_accuracy: 0.8367\n",
            "Epoch 31/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 1.1096 - val_accuracy: 0.8406\n",
            "Epoch 32/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 1.1683 - val_accuracy: 0.8361\n",
            "Epoch 33/50\n",
            "705/705 [==============================] - 30s 43ms/step - loss: 0.0728 - accuracy: 0.9728 - val_loss: 1.2185 - val_accuracy: 0.8334\n",
            "Epoch 34/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0713 - accuracy: 0.9728 - val_loss: 1.2190 - val_accuracy: 0.8365\n",
            "Epoch 35/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 1.1642 - val_accuracy: 0.8394\n",
            "Epoch 36/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0658 - accuracy: 0.9750 - val_loss: 1.2662 - val_accuracy: 0.8347\n",
            "Epoch 37/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0641 - accuracy: 0.9752 - val_loss: 1.2657 - val_accuracy: 0.8341\n",
            "Epoch 38/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0706 - accuracy: 0.9741 - val_loss: 1.3253 - val_accuracy: 0.8352\n",
            "Epoch 39/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0703 - accuracy: 0.9748 - val_loss: 1.3343 - val_accuracy: 0.8359\n",
            "Epoch 40/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0633 - accuracy: 0.9769 - val_loss: 1.3460 - val_accuracy: 0.8328\n",
            "Epoch 41/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0659 - accuracy: 0.9761 - val_loss: 1.3865 - val_accuracy: 0.8342\n",
            "Epoch 42/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0620 - accuracy: 0.9775 - val_loss: 1.3623 - val_accuracy: 0.8387\n",
            "Epoch 43/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0606 - accuracy: 0.9784 - val_loss: 1.3945 - val_accuracy: 0.8359\n",
            "Epoch 44/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 1.4571 - val_accuracy: 0.8313\n",
            "Epoch 45/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0627 - accuracy: 0.9778 - val_loss: 1.5198 - val_accuracy: 0.8330\n",
            "Epoch 46/50\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.0559 - accuracy: 0.9800 - val_loss: 1.5090 - val_accuracy: 0.8340\n",
            "Epoch 47/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 1.5607 - val_accuracy: 0.8346\n",
            "Epoch 48/50\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.0602 - accuracy: 0.9795 - val_loss: 1.5838 - val_accuracy: 0.8374\n",
            "Epoch 49/50\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 1.6071 - val_accuracy: 0.8329\n",
            "Epoch 50/50\n",
            "705/705 [==============================] - 30s 42ms/step - loss: 0.0465 - accuracy: 0.9838 - val_loss: 1.6188 - val_accuracy: 0.8357\n",
            "588/588 [==============================] - 4s 6ms/step - loss: 1.7345 - accuracy: 0.8361\n",
            "Test score: 1.7344574928283691\n",
            "Test accuracy: 0.8361170291900635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "NB_EPOCH = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 47 # number of outputs = number of digits/letters\n",
        "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 1024\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "#X_train is 112800 rows of 28x28 values --> reshaped in 112800 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = input_train.reshape(112800, RESHAPED)\n",
        "X_test = input_test.reshape(18800, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# normalize\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(target_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(target_test, NB_CLASSES)\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=OPTIMIZER,\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,\n",
        "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"Test score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRQnG-NazQvr",
        "outputId": "ef2df75f-a88e-46ec-816d-06ea45d0c7ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112800 train samples\n",
            "18800 test samples\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 47)                48175     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 47)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901,615\n",
            "Trainable params: 1,901,615\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "705/705 [==============================] - 28s 39ms/step - loss: 2.8124 - accuracy: 0.3937 - val_loss: 1.8521 - val_accuracy: 0.5561\n",
            "Epoch 2/50\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 1.5668 - accuracy: 0.5907 - val_loss: 1.3896 - val_accuracy: 0.6207\n",
            "Epoch 3/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 1.3182 - accuracy: 0.6389 - val_loss: 1.2509 - val_accuracy: 0.6518\n",
            "Epoch 4/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 1.2092 - accuracy: 0.6662 - val_loss: 1.1718 - val_accuracy: 0.6679\n",
            "Epoch 5/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 1.1351 - accuracy: 0.6851 - val_loss: 1.1049 - val_accuracy: 0.6890\n",
            "Epoch 6/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 1.0762 - accuracy: 0.7005 - val_loss: 1.0548 - val_accuracy: 0.7015\n",
            "Epoch 7/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 1.0258 - accuracy: 0.7120 - val_loss: 1.0132 - val_accuracy: 0.7118\n",
            "Epoch 8/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.9810 - accuracy: 0.7246 - val_loss: 0.9713 - val_accuracy: 0.7221\n",
            "Epoch 9/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.9407 - accuracy: 0.7343 - val_loss: 0.9413 - val_accuracy: 0.7288\n",
            "Epoch 10/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.9034 - accuracy: 0.7436 - val_loss: 0.9009 - val_accuracy: 0.7389\n",
            "Epoch 11/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.8693 - accuracy: 0.7517 - val_loss: 0.8728 - val_accuracy: 0.7461\n",
            "Epoch 12/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.8382 - accuracy: 0.7596 - val_loss: 0.8460 - val_accuracy: 0.7525\n",
            "Epoch 13/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.8097 - accuracy: 0.7663 - val_loss: 0.8199 - val_accuracy: 0.7603\n",
            "Epoch 14/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.7832 - accuracy: 0.7745 - val_loss: 0.7989 - val_accuracy: 0.7635\n",
            "Epoch 15/50\n",
            "705/705 [==============================] - 28s 39ms/step - loss: 0.7595 - accuracy: 0.7798 - val_loss: 0.7780 - val_accuracy: 0.7703\n",
            "Epoch 16/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.7371 - accuracy: 0.7858 - val_loss: 0.7572 - val_accuracy: 0.7747\n",
            "Epoch 17/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.7165 - accuracy: 0.7908 - val_loss: 0.7395 - val_accuracy: 0.7787\n",
            "Epoch 18/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.6970 - accuracy: 0.7950 - val_loss: 0.7236 - val_accuracy: 0.7836\n",
            "Epoch 19/50\n",
            "705/705 [==============================] - 28s 39ms/step - loss: 0.6791 - accuracy: 0.7997 - val_loss: 0.7057 - val_accuracy: 0.7887\n",
            "Epoch 20/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.6628 - accuracy: 0.8044 - val_loss: 0.6949 - val_accuracy: 0.7911\n",
            "Epoch 21/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.6470 - accuracy: 0.8075 - val_loss: 0.6830 - val_accuracy: 0.7914\n",
            "Epoch 22/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.6328 - accuracy: 0.8104 - val_loss: 0.6698 - val_accuracy: 0.7961\n",
            "Epoch 23/50\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.6193 - accuracy: 0.8151 - val_loss: 0.6591 - val_accuracy: 0.7992\n",
            "Epoch 24/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.6070 - accuracy: 0.8174 - val_loss: 0.6473 - val_accuracy: 0.8029\n",
            "Epoch 25/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.5945 - accuracy: 0.8206 - val_loss: 0.6387 - val_accuracy: 0.8039\n",
            "Epoch 26/50\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.5829 - accuracy: 0.8234 - val_loss: 0.6308 - val_accuracy: 0.8056\n",
            "Epoch 27/50\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.5719 - accuracy: 0.8271 - val_loss: 0.6242 - val_accuracy: 0.8069\n",
            "Epoch 28/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.5617 - accuracy: 0.8288 - val_loss: 0.6120 - val_accuracy: 0.8114\n",
            "Epoch 29/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.5522 - accuracy: 0.8314 - val_loss: 0.6035 - val_accuracy: 0.8135\n",
            "Epoch 30/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.5428 - accuracy: 0.8343 - val_loss: 0.5987 - val_accuracy: 0.8138\n",
            "Epoch 31/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.5340 - accuracy: 0.8360 - val_loss: 0.5924 - val_accuracy: 0.8161\n",
            "Epoch 32/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.5253 - accuracy: 0.8383 - val_loss: 0.5832 - val_accuracy: 0.8168\n",
            "Epoch 33/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.5173 - accuracy: 0.8406 - val_loss: 0.5806 - val_accuracy: 0.8168\n",
            "Epoch 34/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.5095 - accuracy: 0.8434 - val_loss: 0.5754 - val_accuracy: 0.8187\n",
            "Epoch 35/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.5017 - accuracy: 0.8445 - val_loss: 0.5690 - val_accuracy: 0.8211\n",
            "Epoch 36/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4948 - accuracy: 0.8471 - val_loss: 0.5639 - val_accuracy: 0.8230\n",
            "Epoch 37/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4883 - accuracy: 0.8481 - val_loss: 0.5621 - val_accuracy: 0.8203\n",
            "Epoch 38/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4812 - accuracy: 0.8500 - val_loss: 0.5556 - val_accuracy: 0.8234\n",
            "Epoch 39/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4749 - accuracy: 0.8521 - val_loss: 0.5495 - val_accuracy: 0.8261\n",
            "Epoch 40/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4685 - accuracy: 0.8538 - val_loss: 0.5466 - val_accuracy: 0.8254\n",
            "Epoch 41/50\n",
            "705/705 [==============================] - 27s 39ms/step - loss: 0.4631 - accuracy: 0.8552 - val_loss: 0.5431 - val_accuracy: 0.8268\n",
            "Epoch 42/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4569 - accuracy: 0.8568 - val_loss: 0.5391 - val_accuracy: 0.8258\n",
            "Epoch 43/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4517 - accuracy: 0.8576 - val_loss: 0.5342 - val_accuracy: 0.8285\n",
            "Epoch 44/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4459 - accuracy: 0.8601 - val_loss: 0.5354 - val_accuracy: 0.8279\n",
            "Epoch 45/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4409 - accuracy: 0.8613 - val_loss: 0.5305 - val_accuracy: 0.8288\n",
            "Epoch 46/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4353 - accuracy: 0.8627 - val_loss: 0.5254 - val_accuracy: 0.8306\n",
            "Epoch 47/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4310 - accuracy: 0.8639 - val_loss: 0.5228 - val_accuracy: 0.8324\n",
            "Epoch 48/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4257 - accuracy: 0.8651 - val_loss: 0.5182 - val_accuracy: 0.8327\n",
            "Epoch 49/50\n",
            "705/705 [==============================] - 29s 40ms/step - loss: 0.4214 - accuracy: 0.8665 - val_loss: 0.5155 - val_accuracy: 0.8329\n",
            "Epoch 50/50\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.4167 - accuracy: 0.8678 - val_loss: 0.5139 - val_accuracy: 0.8335\n",
            "588/588 [==============================] - 3s 6ms/step - loss: 0.5316 - accuracy: 0.8305\n",
            "Test score: 0.5316038131713867\n",
            "Test accuracy: 0.830531895160675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "NB_EPOCH = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 47 # number of outputs = number of digits/letters\n",
        "OPTIMIZER = RMSprop() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 1024\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "#X_train is 112800 rows of 28x28 values --> reshaped in 112800 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = input_train.reshape(112800, RESHAPED)\n",
        "X_test = input_test.reshape(18800, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# normalize\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(target_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(target_test, NB_CLASSES)\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=OPTIMIZER,\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,\n",
        "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"Test score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU8Bq3uHzQvs",
        "outputId": "0da5fbe8-a8c4-4401-a978-277af7d27e7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112800 train samples\n",
            "18800 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 47)                48175     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 47)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901,615\n",
            "Trainable params: 1,901,615\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.8484 - accuracy: 0.7369 - val_loss: 0.5755 - val_accuracy: 0.8117\n",
            "Epoch 2/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.4801 - accuracy: 0.8365 - val_loss: 0.4950 - val_accuracy: 0.8338\n",
            "Epoch 3/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.3962 - accuracy: 0.8607 - val_loss: 0.4920 - val_accuracy: 0.8398\n",
            "Epoch 4/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.3468 - accuracy: 0.8758 - val_loss: 0.5054 - val_accuracy: 0.8375\n",
            "Epoch 5/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.3129 - accuracy: 0.8861 - val_loss: 0.5359 - val_accuracy: 0.8420\n",
            "Epoch 6/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.2889 - accuracy: 0.8935 - val_loss: 0.5616 - val_accuracy: 0.8412\n",
            "Epoch 7/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.2687 - accuracy: 0.9010 - val_loss: 0.6010 - val_accuracy: 0.8426\n",
            "Epoch 8/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.2542 - accuracy: 0.9043 - val_loss: 0.6312 - val_accuracy: 0.8359\n",
            "Epoch 9/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.2432 - accuracy: 0.9097 - val_loss: 0.6860 - val_accuracy: 0.8434\n",
            "Epoch 10/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.2327 - accuracy: 0.9141 - val_loss: 0.7429 - val_accuracy: 0.8383\n",
            "Epoch 11/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.2205 - accuracy: 0.9167 - val_loss: 0.7891 - val_accuracy: 0.8367\n",
            "Epoch 12/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.2150 - accuracy: 0.9197 - val_loss: 0.8783 - val_accuracy: 0.8360\n",
            "Epoch 13/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.2075 - accuracy: 0.9219 - val_loss: 0.8459 - val_accuracy: 0.8303\n",
            "Epoch 14/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.2044 - accuracy: 0.9232 - val_loss: 0.9295 - val_accuracy: 0.8358\n",
            "Epoch 15/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1982 - accuracy: 0.9259 - val_loss: 0.9263 - val_accuracy: 0.8369\n",
            "Epoch 16/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1960 - accuracy: 0.9274 - val_loss: 1.0391 - val_accuracy: 0.8366\n",
            "Epoch 17/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1930 - accuracy: 0.9295 - val_loss: 1.0944 - val_accuracy: 0.8288\n",
            "Epoch 18/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1886 - accuracy: 0.9306 - val_loss: 1.1375 - val_accuracy: 0.8332\n",
            "Epoch 19/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1856 - accuracy: 0.9325 - val_loss: 1.1964 - val_accuracy: 0.8310\n",
            "Epoch 20/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1828 - accuracy: 0.9334 - val_loss: 1.2227 - val_accuracy: 0.8359\n",
            "Epoch 21/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1798 - accuracy: 0.9354 - val_loss: 1.2084 - val_accuracy: 0.8365\n",
            "Epoch 22/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1811 - accuracy: 0.9368 - val_loss: 1.3020 - val_accuracy: 0.8312\n",
            "Epoch 23/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1688 - accuracy: 0.9393 - val_loss: 1.4949 - val_accuracy: 0.8339\n",
            "Epoch 24/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1738 - accuracy: 0.9381 - val_loss: 1.4004 - val_accuracy: 0.8359\n",
            "Epoch 25/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1698 - accuracy: 0.9398 - val_loss: 1.4875 - val_accuracy: 0.8300\n",
            "Epoch 26/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1706 - accuracy: 0.9407 - val_loss: 1.5411 - val_accuracy: 0.8390\n",
            "Epoch 27/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1690 - accuracy: 0.9415 - val_loss: 1.5893 - val_accuracy: 0.8236\n",
            "Epoch 28/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1673 - accuracy: 0.9416 - val_loss: 1.6957 - val_accuracy: 0.8307\n",
            "Epoch 29/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1645 - accuracy: 0.9439 - val_loss: 1.6778 - val_accuracy: 0.8331\n",
            "Epoch 30/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1632 - accuracy: 0.9451 - val_loss: 1.7531 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1631 - accuracy: 0.9462 - val_loss: 1.7932 - val_accuracy: 0.8350\n",
            "Epoch 32/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1556 - accuracy: 0.9467 - val_loss: 1.8601 - val_accuracy: 0.8295\n",
            "Epoch 33/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1607 - accuracy: 0.9462 - val_loss: 2.0368 - val_accuracy: 0.8315\n",
            "Epoch 34/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1557 - accuracy: 0.9483 - val_loss: 1.9938 - val_accuracy: 0.8333\n",
            "Epoch 35/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1565 - accuracy: 0.9482 - val_loss: 2.0062 - val_accuracy: 0.8324\n",
            "Epoch 36/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1540 - accuracy: 0.9496 - val_loss: 2.0267 - val_accuracy: 0.8318\n",
            "Epoch 37/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1540 - accuracy: 0.9496 - val_loss: 2.0890 - val_accuracy: 0.8292\n",
            "Epoch 38/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1499 - accuracy: 0.9510 - val_loss: 2.2771 - val_accuracy: 0.8299\n",
            "Epoch 39/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1493 - accuracy: 0.9510 - val_loss: 2.3335 - val_accuracy: 0.8277\n",
            "Epoch 40/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1530 - accuracy: 0.9507 - val_loss: 2.2581 - val_accuracy: 0.8305\n",
            "Epoch 41/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1503 - accuracy: 0.9519 - val_loss: 2.2147 - val_accuracy: 0.8344\n",
            "Epoch 42/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1438 - accuracy: 0.9526 - val_loss: 2.3440 - val_accuracy: 0.8301\n",
            "Epoch 43/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1486 - accuracy: 0.9542 - val_loss: 2.3696 - val_accuracy: 0.8305\n",
            "Epoch 44/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1509 - accuracy: 0.9531 - val_loss: 2.4329 - val_accuracy: 0.8320\n",
            "Epoch 45/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 2.5218 - val_accuracy: 0.8353\n",
            "Epoch 46/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1419 - accuracy: 0.9555 - val_loss: 2.7326 - val_accuracy: 0.8301\n",
            "Epoch 47/50\n",
            "705/705 [==============================] - 33s 47ms/step - loss: 0.1469 - accuracy: 0.9557 - val_loss: 2.7111 - val_accuracy: 0.8266\n",
            "Epoch 48/50\n",
            "705/705 [==============================] - 33s 46ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 2.5441 - val_accuracy: 0.8336\n",
            "Epoch 49/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.1401 - accuracy: 0.9566 - val_loss: 2.7698 - val_accuracy: 0.8289\n",
            "Epoch 50/50\n",
            "705/705 [==============================] - 32s 46ms/step - loss: 0.1428 - accuracy: 0.9569 - val_loss: 2.8109 - val_accuracy: 0.8344\n",
            "588/588 [==============================] - 4s 6ms/step - loss: 3.0420 - accuracy: 0.8304\n",
            "Test score: 3.0419535636901855\n",
            "Test accuracy: 0.8304255604743958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adam() has the highest test accuracy at 0.83611\n",
        "# Accuracy can be improved by implementing 250 epochs or even up to 500 taking batch size as 8"
      ],
      "metadata": {
        "id": "Tn6GraLm7o3Q"
      }
    }
  ]
}