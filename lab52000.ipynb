{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Different Neural Network layers and Neural Network Architecture\nLayers**\n\n* >**Input**\n* >**BatchNormalisation**\n* >**Dense**\n* >**Conv**\n* >**Pool**\n\n**Architectures**\n\n* >**Keras Sequential API**\n>* >**LeNET designed with Sequential API**\n* >**Keras Functional API**\n>* >**WilliamNet designed with Functional API**\n\n**Design AlexNet with Sequential as well as Functional API**\n\n>* >**AlexNet**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:30:30.989167Z","iopub.execute_input":"2022-03-08T16:30:30.990244Z","iopub.status.idle":"2022-03-08T16:30:38.295705Z","shell.execute_reply.started":"2022-03-08T16:30:30.990094Z","shell.execute_reply":"2022-03-08T16:30:38.294655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data\ntrain_datagen_with_no_transforms = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255)\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1./255)\n\ntrain_generator = train_datagen_with_no_transforms.flow_from_directory(\n    '../input/emotion-detection-fer/train',\n    target_size=(32, 32),\n    batch_size=32,\n    class_mode=\"sparse\"\n)\nvalidation_generator = val_datagen.flow_from_directory(\n    '../input/emotion-detection-fer/test',\n    target_size=(32, 32),\n    batch_size=32,\n    class_mode=\"sparse\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:30:55.195828Z","iopub.execute_input":"2022-03-08T16:30:55.196163Z","iopub.status.idle":"2022-03-08T16:31:07.472052Z","shell.execute_reply.started":"2022-03-08T16:30:55.196129Z","shell.execute_reply":"2022-03-08T16:31:07.470966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = next(validation_generator)\nsample_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:31:37.65034Z","iopub.execute_input":"2022-03-08T16:31:37.650705Z","iopub.status.idle":"2022-03-08T16:31:37.882963Z","shell.execute_reply.started":"2022-03-08T16:31:37.650664Z","shell.execute_reply":"2022-03-08T16:31:37.882072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_train_samples = train_generator.samples\nnb_val_samples = validation_generator.samples\ntrain_generator.samples","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:31:40.818077Z","iopub.execute_input":"2022-03-08T16:31:40.818718Z","iopub.status.idle":"2022-03-08T16:31:40.824587Z","shell.execute_reply.started":"2022-03-08T16:31:40.818677Z","shell.execute_reply":"2022-03-08T16:31:40.823899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ARCHITECTURE\n# BUILDING A MODEL WITH KERAS SEQUENTIAL API","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LeNet SEQUENTIAL MODEL1","metadata":{}},{"cell_type":"code","source":"# LeNET model\nmodel = models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(32,32,3)))\nmodel.add(tf.keras.layers.MaxPool2D(strides=2))\nmodel.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D(strides=2))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(84, activation='relu'))\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:31:50.541749Z","iopub.execute_input":"2022-03-08T16:31:50.542067Z","iopub.status.idle":"2022-03-08T16:31:50.760563Z","shell.execute_reply.started":"2022-03-08T16:31:50.542036Z","shell.execute_reply":"2022-03-08T16:31:50.759534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:31:56.709741Z","iopub.execute_input":"2022-03-08T16:31:56.710086Z","iopub.status.idle":"2022-03-08T16:31:56.729589Z","shell.execute_reply.started":"2022-03-08T16:31:56.710052Z","shell.execute_reply":"2022-03-08T16:31:56.728569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, epochs=100, validation_data=validation_generator,validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:32:01.516488Z","iopub.execute_input":"2022-03-08T16:32:01.517025Z","iopub.status.idle":"2022-03-08T16:32:18.614756Z","shell.execute_reply.started":"2022-03-08T16:32:01.516969Z","shell.execute_reply":"2022-03-08T16:32:18.613274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_generator, batch_size=2000, epochs=100,verbose=1,callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T16:32:23.490303Z","iopub.execute_input":"2022-03-08T16:32:23.491249Z","iopub.status.idle":"2022-03-08T18:25:21.938024Z","shell.execute_reply.started":"2022-03-08T16:32:23.491204Z","shell.execute_reply":"2022-03-08T18:25:21.936008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T18:27:04.525591Z","iopub.execute_input":"2022-03-08T18:27:04.526035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AlexNet SEQUENTIAL MODEL 1","metadata":{}},{"cell_type":"code","source":"input_shape=(32, 32, 3) \nnum_classes = 7\n# AlexNET model\nseq_alex = models.Sequential()\n#seq_alex.add() # input shape must be specified according to the input data dimension\n#seq_alex.add()\n\nseq_alex.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n                        padding= 'valid', activation= 'relu',\n                        input_shape= input_shape,\n                        kernel_initializer= 'he_normal'))\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None))\n\nseq_alex.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None)) \n\nseq_alex.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nseq_alex.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n                              padding= 'same', data_format= None))\n\nseq_alex.add(Flatten())\nseq_alex.add(Dense(4096, activation= 'relu'))\nseq_alex.add(Dense(4096, activation= 'relu'))\nseq_alex.add(Dense(1000, activation= 'relu'))\nseq_alex.add(Dense(num_classes, activation= 'softmax'))\n\nseq_alex.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:42:48.295915Z","iopub.execute_input":"2022-03-07T07:42:48.296579Z","iopub.status.idle":"2022-03-07T07:42:48.390098Z","shell.execute_reply.started":"2022-03-07T07:42:48.296539Z","shell.execute_reply":"2022-03-07T07:42:48.389357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nseq_alex.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:43:24.118045Z","iopub.execute_input":"2022-03-07T07:43:24.118647Z","iopub.status.idle":"2022-03-07T07:43:24.130289Z","shell.execute_reply.started":"2022-03-07T07:43:24.11861Z","shell.execute_reply":"2022-03-07T07:43:24.129372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = seq_alex.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:43:53.890534Z","iopub.execute_input":"2022-03-07T07:43:53.890839Z","iopub.status.idle":"2022-03-07T07:45:35.169485Z","shell.execute_reply.started":"2022-03-07T07:43:53.890801Z","shell.execute_reply":"2022-03-07T07:45:35.166643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_alex.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nseq_alex.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:45:47.485074Z","iopub.execute_input":"2022-03-07T07:45:47.485334Z","iopub.status.idle":"2022-03-07T07:46:59.55715Z","shell.execute_reply.started":"2022-03-07T07:45:47.485304Z","shell.execute_reply":"2022-03-07T07:46:59.555675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BUILDING A MODEL WITH KERAS FUNCTIONAL API","metadata":{}},{"cell_type":"markdown","source":"# WILLIAMNET FUNCTIONAL API","metadata":{}},{"cell_type":"code","source":"input_shape=(32, 32, 3) #( 40, 11, 1)\nnum_classes = 7\n\n\"\"\" keras williamnet description \"\"\"\ninputs = tf.keras.layers.Input(shape=input_shape)\n# first conv layer\nx = tf.keras.layers.Conv2D(128, (5, 3), padding=\"same\")(inputs)\nx = tf.keras.layers.Activation('relu')(x)\n\nx = tf.keras.layers.Conv2D(256, (5, 3), padding=\"same\")(x)\nx = tf.keras.layers.Activation('relu')(x)\n\nx = tf.keras.layers.Conv2D(384, (3, 3), padding=\"same\")(x)\nx = tf.keras.layers.Activation('relu')(x)\nx = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\nx = tf.keras.layers.Conv2D(384, (3, 3), padding=\"same\")(x)\nx = tf.keras.layers.Activation('relu')(x)\nx = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\nx = tf.keras.layers.Flatten()(x)\n\nx = tf.keras.layers.Dense(256)(x)\nx = tf.keras.layers.Dense(num_classes)(x)\nx = tf.keras.layers.Softmax()(x)\n\nmodel = models.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T02:23:35.201249Z","iopub.execute_input":"2022-03-07T02:23:35.201517Z","iopub.status.idle":"2022-03-07T02:23:37.619894Z","shell.execute_reply.started":"2022-03-07T02:23:35.201489Z","shell.execute_reply":"2022-03-07T02:23:37.618062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T02:23:41.789685Z","iopub.execute_input":"2022-03-07T02:23:41.791938Z","iopub.status.idle":"2022-03-07T02:23:41.814309Z","shell.execute_reply.started":"2022-03-07T02:23:41.791893Z","shell.execute_reply":"2022-03-07T02:23:41.813645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback ]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T02:23:44.976674Z","iopub.execute_input":"2022-03-07T02:23:44.977297Z","iopub.status.idle":"2022-03-07T02:29:41.174153Z","shell.execute_reply.started":"2022-03-07T02:23:44.977257Z","shell.execute_reply":"2022-03-07T02:29:41.172017Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_generator, batch_size=2000, epochs=100,verbose=1,callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T02:29:46.6212Z","iopub.execute_input":"2022-03-07T02:29:46.621491Z","iopub.status.idle":"2022-03-07T02:30:56.262282Z","shell.execute_reply.started":"2022-03-07T02:29:46.621461Z","shell.execute_reply":"2022-03-07T02:30:56.261056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALEXNET FUNCTIONAL API","metadata":{}},{"cell_type":"code","source":"#from keras import backend as K  \n#K.image_data_format('th')  \n\n#from keras import backend as K  \n#K.image_data_format('tf')\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np \n# Do\n# AlexNET model with functional API\ninputs = tf.keras.layers.Input(shape=input_shape) # input shape must be specified according to the input data dimension\n#x = tf.keras.layers.Conv2D()(inputs)\n#x = tf.keras.layers.MaxPool2D()(x)\n\n#functional_alex = models.Model(inputs=inputs, outputs=)\n\n#X_input = Input(input_shape)   \nX = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(inputs)\nX = BatchNormalization(axis = 3 , name = \"bn0\")(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max0',padding='same')(X)\n    \nX = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\nX = BatchNormalization(axis = 3 ,name='bn1')(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max1',padding='same')(X)\n    \nX = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\nX = BatchNormalization(axis = 3, name = 'bn2')(X)\nX = Activation('relu')(X)\n    \nX = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\nX = BatchNormalization(axis = 3, name = 'bn3')(X)\nX = Activation('relu')(X)\n    \nX = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\nX = BatchNormalization(axis = 3, name = 'bn4')(X)\nX = Activation('relu')(X)\n    \nX = MaxPooling2D((3,3),strides = 2,name = 'max2',padding='same')(X)\n    \nX = Flatten()(X)\n    \nX = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n    \nX = Dense(4096, activation = 'relu', name = 'fc1')(X) \n    \nX = Dense(1000,activation='softmax',name = 'fc2')(X) \n    \nmodel = Model(inputs = inputs, outputs = X, name='AlexNet')","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:41:16.694094Z","iopub.execute_input":"2022-03-07T04:41:16.694596Z","iopub.status.idle":"2022-03-07T04:41:16.81999Z","shell.execute_reply.started":"2022-03-07T04:41:16.694557Z","shell.execute_reply":"2022-03-07T04:41:16.8193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:41:22.408506Z","iopub.execute_input":"2022-03-07T04:41:22.409068Z","iopub.status.idle":"2022-03-07T04:41:22.420576Z","shell.execute_reply.started":"2022-03-07T04:41:22.409027Z","shell.execute_reply":"2022-03-07T04:41:22.419716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\n# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:41:28.413977Z","iopub.execute_input":"2022-03-07T04:41:28.414454Z","iopub.status.idle":"2022-03-07T04:47:47.939232Z","shell.execute_reply.started":"2022-03-07T04:41:28.414415Z","shell.execute_reply":"2022-03-07T04:47:47.938494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALEXNET SEQUENTIAL API","metadata":{}},{"cell_type":"code","source":"#Importing library\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nimport numpy as np\n\nnp.random.seed(1000)\n\n#Instantiation\nAlexNet = Sequential()\n\n#1st Convolutional Layer\nAlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#2nd Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#3rd Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#4th Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#5th Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#Passing it to a Fully Connected layer\nAlexNet.add(Flatten())\n# 1st Fully Connected Layer\nAlexNet.add(Dense(4096, input_shape=(32,32,3,)))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nAlexNet.add(Dropout(0.4))\n\n#2nd Fully Connected Layer\nAlexNet.add(Dense(4096))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#3rd Fully Connected Layer\nAlexNet.add(Dense(1000))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#Output Layer\nAlexNet.add(Dense(10))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('softmax'))\n\n#Model Summary\nAlexNet.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T05:25:54.613594Z","iopub.execute_input":"2022-03-07T05:25:54.613966Z","iopub.status.idle":"2022-03-07T05:25:54.845399Z","shell.execute_reply.started":"2022-03-07T05:25:54.61393Z","shell.execute_reply":"2022-03-07T05:25:54.8447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AlexNet.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T05:26:05.137201Z","iopub.execute_input":"2022-03-07T05:26:05.137499Z","iopub.status.idle":"2022-03-07T05:26:05.148217Z","shell.execute_reply.started":"2022-03-07T05:26:05.137465Z","shell.execute_reply":"2022-03-07T05:26:05.147362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) ","metadata":{"execution":{"iopub.status.busy":"2022-03-07T05:26:07.58974Z","iopub.execute_input":"2022-03-07T05:26:07.590315Z","iopub.status.idle":"2022-03-07T05:26:07.595849Z","shell.execute_reply.started":"2022-03-07T05:26:07.590278Z","shell.execute_reply":"2022-03-07T05:26:07.593583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001","metadata":{"execution":{"iopub.status.busy":"2022-03-07T05:26:09.096143Z","iopub.execute_input":"2022-03-07T05:26:09.096565Z","iopub.status.idle":"2022-03-07T05:26:09.101214Z","shell.execute_reply.started":"2022-03-07T05:26:09.096524Z","shell.execute_reply":"2022-03-07T05:26:09.100534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the model\nAlexNet.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T05:26:11.987237Z","iopub.execute_input":"2022-03-07T05:26:11.987534Z","iopub.status.idle":"2022-03-07T05:57:25.040541Z","shell.execute_reply.started":"2022-03-07T05:26:11.987501Z","shell.execute_reply":"2022-03-07T05:57:25.037973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.pooling import MaxPool2D\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:46:22.200106Z","iopub.execute_input":"2022-03-07T03:46:22.200367Z","iopub.status.idle":"2022-03-07T03:46:22.207518Z","shell.execute_reply.started":"2022-03-07T03:46:22.200335Z","shell.execute_reply":"2022-03-07T03:46:22.206424Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LeNet KERAS SEQUENTIAL API","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(7, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:10:54.95509Z","iopub.execute_input":"2022-03-07T07:10:54.955972Z","iopub.status.idle":"2022-03-07T07:10:55.011153Z","shell.execute_reply.started":"2022-03-07T07:10:54.955933Z","shell.execute_reply":"2022-03-07T07:10:55.010461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nadam = Adam(lr=5e-4)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:10:58.726104Z","iopub.execute_input":"2022-03-07T07:10:58.726744Z","iopub.status.idle":"2022-03-07T07:10:58.736872Z","shell.execute_reply.started":"2022-03-07T07:10:58.726698Z","shell.execute_reply":"2022-03-07T07:10:58.736083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n# Set a learning rate annealer\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.2, min_lr=1e-6)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:11:01.662532Z","iopub.execute_input":"2022-03-07T07:11:01.663288Z","iopub.status.idle":"2022-03-07T07:11:01.667935Z","shell.execute_reply.started":"2022-03-07T07:11:01.663239Z","shell.execute_reply":"2022-03-07T07:11:01.667021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:11:27.783009Z","iopub.execute_input":"2022-03-07T07:11:27.783279Z","iopub.status.idle":"2022-03-07T07:13:38.395755Z","shell.execute_reply.started":"2022-03-07T07:11:27.783246Z","shell.execute_reply":"2022-03-07T07:13:38.392665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LENET SEQUENTIAL","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=(32,32,3), padding='same'), #C1\n    keras.layers.AveragePooling2D(), #S2\n    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3\n    keras.layers.AveragePooling2D(), #S4\n    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C5\n    keras.layers.Flatten(), #Flatten    \n    keras.layers.Dense(84, activation='tanh'), #F6\n    keras.layers.Dense(10, activation='softmax') #Output layer\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:13:39.911026Z","iopub.execute_input":"2022-03-07T04:13:39.911822Z","iopub.status.idle":"2022-03-07T04:13:39.96887Z","shell.execute_reply.started":"2022-03-07T04:13:39.911736Z","shell.execute_reply":"2022-03-07T04:13:39.968013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:13:42.993029Z","iopub.execute_input":"2022-03-07T04:13:42.993514Z","iopub.status.idle":"2022-03-07T04:13:43.00408Z","shell.execute_reply.started":"2022-03-07T04:13:42.993477Z","shell.execute_reply":"2022-03-07T04:13:43.00323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T04:13:45.454286Z","iopub.execute_input":"2022-03-07T04:13:45.454616Z","iopub.status.idle":"2022-03-07T04:19:53.92615Z","shell.execute_reply.started":"2022-03-07T04:13:45.454575Z","shell.execute_reply":"2022-03-07T04:19:53.925303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LENET SEQUENTIAL","metadata":{}},{"cell_type":"code","source":"from keras.layers.pooling import AveragePooling2D","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:06:34.28137Z","iopub.execute_input":"2022-03-07T07:06:34.281688Z","iopub.status.idle":"2022-03-07T07:06:34.28548Z","shell.execute_reply.started":"2022-03-07T07:06:34.281653Z","shell.execute_reply":"2022-03-07T07:06:34.28484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), activation='tanh', input_shape=(32,32,3)))\nmodel.add(AveragePooling2D())\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='tanh'))\nmodel.add(AveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation='tanh'))\nmodel.add(Dense(units=10, activation = 'softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:07:12.993512Z","iopub.execute_input":"2022-03-07T07:07:12.993805Z","iopub.status.idle":"2022-03-07T07:07:13.048486Z","shell.execute_reply.started":"2022-03-07T07:07:12.993755Z","shell.execute_reply":"2022-03-07T07:07:13.047817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:07:16.417298Z","iopub.execute_input":"2022-03-07T07:07:16.417854Z","iopub.status.idle":"2022-03-07T07:07:16.428194Z","shell.execute_reply.started":"2022-03-07T07:07:16.417811Z","shell.execute_reply":"2022-03-07T07:07:16.427423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncallback_list = [ early_stopping_callback]\n\n# train\nhistory = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples/2000, \n                    epochs=100, validation_data=validation_generator,\n                    validation_steps=nb_val_samples/2000, callbacks=callback_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:07:19.691636Z","iopub.execute_input":"2022-03-07T07:07:19.692191Z","iopub.status.idle":"2022-03-07T07:08:04.325161Z","shell.execute_reply.started":"2022-03-07T07:07:19.692153Z","shell.execute_reply":"2022-03-07T07:08:04.322596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n\n#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001\n\nmodel.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T07:08:58.735155Z","iopub.execute_input":"2022-03-07T07:08:58.735449Z","iopub.status.idle":"2022-03-07T07:09:18.222697Z","shell.execute_reply.started":"2022-03-07T07:08:58.735416Z","shell.execute_reply":"2022-03-07T07:09:18.221703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LENET SEQUENTIAL","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.pooling import MaxPooling2D\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np\nfrom tensorflow.keras.optimizers import SGD","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:10:12.34008Z","iopub.execute_input":"2022-03-07T06:10:12.340352Z","iopub.status.idle":"2022-03-07T06:10:12.346461Z","shell.execute_reply.started":"2022-03-07T06:10:12.340315Z","shell.execute_reply":"2022-03-07T06:10:12.345739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_classes=7\n# Create a sequential model\nmodel = Sequential()\n\n# Add the first convolution layer\nmodel.add(Convolution2D(\n    filters = 20,\n    kernel_size = (5, 5),\n    padding = \"same\",\n    input_shape = (32, 32, 3)))\n\n# Add a ReLU activation function\nmodel.add(Activation(\n    activation = \"relu\"))\n\n# Add a pooling layer\nmodel.add(MaxPooling2D(\n    pool_size = (2, 2),\n    strides =  (2, 2)))\n\n# Add the second convolution layer\nmodel.add(Convolution2D(\n    filters = 50,\n    kernel_size = (5, 5),\n    padding = \"same\"))\n\n# Add a ReLU activation function\nmodel.add(Activation(\n    activation = \"relu\"))\n\n# Add a second pooling layer\nmodel.add(MaxPooling2D(\n    pool_size = (2, 2),\n    strides = (2, 2)))\n\n# Flatten the network\nmodel.add(Flatten())\n\n# Add a fully-connected hidden layer\nmodel.add(Dense(500))\n\n# Add a ReLU activation function\nmodel.add(Activation(\n    activation = \"relu\"))\n\n# Add a fully-connected output layer\nmodel.add(Dense(nb_classes))\n\n# Add a softmax activation function\nmodel.add(Activation(\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:18:45.775825Z","iopub.execute_input":"2022-03-07T06:18:45.776534Z","iopub.status.idle":"2022-03-07T06:18:45.835313Z","shell.execute_reply.started":"2022-03-07T06:18:45.776496Z","shell.execute_reply":"2022-03-07T06:18:45.834645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer_fn,\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:21:13.574787Z","iopub.execute_input":"2022-03-07T06:21:13.575389Z","iopub.status.idle":"2022-03-07T06:21:13.58506Z","shell.execute_reply.started":"2022-03-07T06:21:13.575351Z","shell.execute_reply":"2022-03-07T06:21:13.58432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning Rate Annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:21:47.267956Z","iopub.execute_input":"2022-03-07T06:21:47.268501Z","iopub.status.idle":"2022-03-07T06:21:47.272865Z","shell.execute_reply.started":"2022-03-07T06:21:47.268464Z","shell.execute_reply":"2022-03-07T06:21:47.272052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining the parameters\nbatch_size= 2000\nepochs=100\nlearn_rate=.001","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:21:57.960218Z","iopub.execute_input":"2022-03-07T06:21:57.960494Z","iopub.status.idle":"2022-03-07T06:21:57.964416Z","shell.execute_reply.started":"2022-03-07T06:21:57.960463Z","shell.execute_reply":"2022-03-07T06:21:57.963723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs = epochs, validation_data = validation_generator, validation_steps = 250, callbacks = [lrr], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:22:16.325732Z","iopub.execute_input":"2022-03-07T06:22:16.326079Z","iopub.status.idle":"2022-03-07T07:04:11.356793Z","shell.execute_reply.started":"2022-03-07T06:22:16.326042Z","shell.execute_reply":"2022-03-07T07:04:11.35568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}